# **0424**

- Gemini-pro와 GPT-4를 대상으로 챗봇 QA
    - Gemini-pro의 경우 로컬에서 진행하였으며, amadeus와 인증 절차등을 제거한 코드에서 진행함
    - 응답까지 걸리는 속도, 응답의 퀄리티, 문제점 확인
        - 똑같은 프롬프트 템플릿이어도 검색된 웹 정보에 따라 답변의 퀄리티가 좌지우지 되는 경향이 발생
        - 예를 들어, 예산이나 호텔, 교통 정보가 있는 것과 없는 정도의 차이가 있음
    - 결과적으로는 GPT-4의 답변 퀄리티가 훨씬 좋았으나, 아래에서 지적되는 것과 동일하게 생성 응답 속도가 느림
- 응답 속도가 전체적으로 평균 2분에서 3분이 걸림(30회 기준 평균 128초, None 값 제외)
    - GPT-4와 Gemini의 차이가 거의 없는 것으로 보아 모델의 문제가 아닌 것으로 보임
    - 이를 더 줄일 수 있는 기술적 방안이 필요
        - (claude3曰) from functools import lru_cache → @lru_cache(maxsize=128) → 효과 미미
        - (claude3曰) asyncio 라이브러리 → 비동기 병렬처리를 통해 코드 개선 시도 → 효과 미미(코드를 잘못 만들어서 그런지 모르겠음)
        - agent의 temperature, max_iterations를 낮추기, max_output_tokens 제한하기 → 프롬프트 등의 다른 이유로 정확한 판단 어려움(0 제외)
        - 프롬프트의 template 개선 → 구체적인 템플릿을 만들수록 역질문과 루프 등으로 인해 다수의 에러 발생 → 현재로선 극적인 개선은 실패
    - 혹시나 대화 내용을 통해 좀 더 다른 방향을 제시해줄 것을 생각해서 “ConversationBufferWindowMemory”의 k값을 늘려보았으나, 별 다른 차이를 못 느꼈음(미미)
    

- 개인적인 생각
    - 프롬프트 템플릿을 개선시에 에 ‘여행 인원, 여행 날짜, 관계, 예산 등’의 입력값이 없을 경우, 역으로 질문이 돌거나, tools를 사용하지 못하고 action이 이루어지지 않는 등의 상황이 발생함 → 디테일한 개선을 원할 시, 동시에 코드에서도 역으로 질문이 나오면 다시 입력을 하는 소위 ‘티키타카’가 이루어지는 방향이 필요함
    - 즉, 디테일이냐 대략적인 정보로 만드는 계획에서 끝내느냐에 대한 선택이 필요해 보임
    - 현재까지로서는 속도 개선은 사실상 temperature를 극단적으로 줄이는 방향 밖에 생각이 안 남 → 이러면 챗봇 ‘인공지능’이 의미가 없긴함
