# 0425

> 오늘도 firebase, auth 등의 절차를 제거하고 로컬에서 실험
> 

<aside>
✅ 발견된 문제점

- ~~새로운 질문을 했을 때, 기존의 대화 내역이 초기화되지 않음~~
    - ~~현재 올려져있는 서버에서 ‘채팅 내용 삭제’ 시 메모리에 저장된 내용이 지워지면 상관없으나 그게 아니면 개선이 필요~~
    - 채팅 DB 삭제 시 메모리도 지워짐, 해결
- 현재 프롬프트 템플릿은 정보를 제한적으로 제공 시 ‘가끔’ 질문을 다시 함(Gemini-Pro) 기준
    - GPT-4는 추가적인 정보를 제공해달라고 함, 다만 정보를 제공한다고 해도 답이 늦어지거나, 죽어버림
- GPT-4에서는 모르겠으나, Gemini의 경우 agent가 같은 질문을 계속해서 반복적으로 검색하는 현상이 발견됨
</aside>

> 변경해본 코드
> 
- app_kor.py > def chatbot() > 예외 처리 추가 및 Final Answer가 아니더라도 나오도록 변경 시도
    - 문제는 저렇게 해놔도 observation이나, Final Answer를 웹에 출력 안 함(콘솔에는 결과가 나왔는데)
    - output parser에 문제가 있나?
    
    ```python
    # agent_executor = chatbot_core.agent() 여기 다음 줄
    if query:
                    if len(query) == 0:
                        response = "유효한 질문을 입력해주세요."
                    elif len(query) > 1000:
                        response = "질문이 너무 깁니다. 1000자 이내로 입력해주세요."
                    else:
                        st.session_state[MESSAGES].append(Message(actor=USER, payload=str(query)))
                        st.chat_message(USER).write(query)
                        with st.spinner("생각중이에요..."):
                            start_time = time.time()
                            try:
                                agent_output = agent_executor.invoke({'input': query})['output']
                                if "Observation:" in agent_output:
                                    # Observation이 포함된 경우, 해당 부분을 추출하여 response에 할당
                                    response = agent_output.split("Observation:")[-1].strip()
                                elif "Final Answer:" in agent_output:
                                    response = agent_output.split("Final Answer:")[-1].strip()
                                else:
                                    response = "죄송합니다. 적절한 답변을 생성하지 못했습니다. 질문을 다시 입력해주세요."
                            except Exception as e:
                                response = "에러가 발생했습니다. 다시 시도해주세요."
                                print(f"Error: {str(e)}")
                            end_time = time.time()
                            execution_time = end_time - start_time
                            print(f"Response Generation Time: {execution_time:.2f} seconds")
    ```
    
- 같은 질문을 계속해서 반복적으로 검색하는 현상을 개선하기 위한 변경 시도
    - 검색 결과를 캐싱하기 위한 딕셔너리 생성
    - 의사 결정 로직 개선(함수 추가)
        
        ```python
        from typing import List, Dict
        
        # 검색 결과를 캐싱하기 위한 딕셔너리
        search_cache: Dict[str, str] = {}
        
        def search_general(input_text: str) -> str:
            if input_text in search_cache:
                return search_cache[input_text]
            search_result = DuckDuckGoSearchRun().run(input_text)
            search_cache[input_text] = search_result
            return search_result
        
        def search_online(input_text: str) -> str:
            query = f"site:tripadvisor.com things to do{input_text}"
            if query in search_cache:
                return search_cache[query]
            search_result = DuckDuckGoSearchRun().run(query)
            search_cache[query] = search_result
            return search_result
        
        def search_hotel(input_text: str) -> str:
            query = f"site:agoda.com {input_text}"
            if query in search_cache:
                return search_cache[query]
            search_result = DuckDuckGoSearchRun().run(query)
            search_cache[query] = search_result
            return search_result
        
        def search_flight(input_text: str) -> str:
            query = f"site:skyscanner.com {input_text}"
            if query in search_cache:
                return search_cache[query]
            search_result = DuckDuckGoSearchRun().run(query)
            search_cache[query] = search_result
            return search_result
        
        class CustomOutputParser(AgentOutputParser):
            def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:
                if "Final Answer:" in llm_output:
                    return AgentFinish(
                        return_values={"output": llm_output.split("Final Answer:")[-1].strip()},
                        log=llm_output,
                    )
                elif "Observation:" in llm_output:
                    return AgentAction(tool="Observation", tool_input=llm_output.split("Observation:")[-1].strip(), log=llm_output)
                else:
                    regex = r"Action\s*\d*\s*:(.*?)\nAction\s*\d*\s*Input\s*\d*\s*:[\s]*(.*)"
                    match = re.search(regex, llm_output, re.DOTALL)
                    if not match:
                        return AgentAction(tool="Request reformatting", tool_input="I couldn't understand your output. Please reformat your response following the given template strictly.", log=llm_output)
                    action = match.group(1).strip()
                    action_input = match.group(2)
                    return AgentAction(tool=action, tool_input=action_input.strip(" ").strip('"'), log=llm_output)
        
        def has_sufficient_information(agent_scratchpad: str) -> bool:
            # 에이전트 스크래치패드를 분석하여 충분한 정보가 수집되었는지 판단
            # 여행 날짜, 인원 수, 동행자 정보, 숙소 유형, 여행 스타일 등의 정보가 포함되어 있는지 확인
            required_info = ["여행 날짜", "인원 수", "동행자 정보", "숙소 유형", "여행 스타일"]
            for info in required_info:
                if info not in agent_scratchpad:
                    return False
            return True
        
        @cl.on_chat_start
        def agent():
            tools = [
                # ... (생략) ...
            ]
        
            prompt = CustomPromptTemplate(
                template=template,
                tools=tools,
                input_variables=["input", "intermediate_steps", "history"]
            )
        
            output_parser = CustomOutputParser()
            llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.5)
            llm_chain = LLMChain(llm=llm, prompt=prompt)
        
            tool_names = [tool.name for tool in tools]
            agent = LLMSingleActionAgent(
                llm_chain=llm_chain,
                output_parser=output_parser,
                stop=["\nObservation:"],
                allowed_tools=tool_names
            )
        
            # 에이전트 의사 결정 로직을 개선한 AgentExecutor 생성
            agent_executor = AgentExecutor.from_agent_and_tools(
                agent=agent,
                tools=tools,
                verbose=True,
                memory=memory,
                handle_parsing_errors="Check your output and make sure it conforms, use the Action/Action Input syntax",
                max_iterations=10,
                agent_kwargs={'agent_output_postprocessor': postprocess_agent_output},
                additional_stop_condition=has_sufficient_information
            )
        
            return agent_executor
        ```
        
        - 그럼에도 불구하고, 같은 결과를 검색하는 것 처럼 콘솔에서는 보임.
        - 또한 속도 개선이나, 올바른 답변이 나오는 것도 아님
